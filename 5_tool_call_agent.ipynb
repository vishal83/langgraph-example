{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba0bf513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221a66e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da2aed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73fd740",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_stock_price(symbol: str) -> float:\n",
    "    \"\"\"Fetch the current stock price for a given stock symbol.\n",
    "    \n",
    "    Args:\n",
    "        symbol: The stock ticker symbol (e.g., 'MSFT', 'AAPL', 'GOOG', 'TSLA')\n",
    "    \n",
    "    Returns:\n",
    "        The current price of the stock as a float\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"MSFT\": 234.56,\n",
    "        \"AAPL\": 123.45,\n",
    "        \"GOOG\": 2345.67,\n",
    "        \"TSLA\": 789.01,\n",
    "    }.get(symbol, 0.0)\n",
    "\n",
    "tools = [get_stock_price]\n",
    "\n",
    "llm = init_chat_model(model=\"google_genai:gemini-2.5-flash-lite\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31d42e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def chatbot(state: State) -> State:\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chatbot_node\", chatbot)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"chatbot_node\")\n",
    "builder.add_conditional_edges(\n",
    "    \"chatbot_node\",\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\", \"chatbot_node\")\n",
    "graph = builder.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d84bd7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Simple stock price query ===\n"
     ]
    },
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Error calling model 'gemini-2.5-flash-lite' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 8.562794299s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:3040\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m   3039\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3040\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m   3041\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest,\n\u001b[0;32m   3042\u001b[0m     )\n\u001b[0;32m   3043\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\google\\genai\\models.py:5188\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   5181\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   5182\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTools at indices [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] are not compatible with automatic function \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   5183\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalling (AFC). AFC is disabled. If AFC is intended, please \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5186\u001b[0m         indices_str,\n\u001b[0;32m   5187\u001b[0m     )\n\u001b[1;32m-> 5188\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5189\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparsed_config\u001b[49m\n\u001b[0;32m   5190\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5192\u001b[0m remaining_remote_calls_afc \u001b[38;5;241m=\u001b[39m _extra_utils\u001b[38;5;241m.\u001b[39mget_max_remote_calls_afc(\n\u001b[0;32m   5193\u001b[0m     parsed_config\n\u001b[0;32m   5194\u001b[0m )\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\google\\genai\\models.py:3985\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   3983\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[1;32m-> 3985\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3986\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[0;32m   3987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[0;32m   3990\u001b[0m     config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould_return_http_response\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3991\u001b[0m ):\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\google\\genai\\_api_client.py:1388\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[1;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[0;32m   1385\u001b[0m http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[0;32m   1386\u001b[0m     http_method, path, request_dict, http_options\n\u001b[0;32m   1387\u001b[0m )\n\u001b[1;32m-> 1388\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1389\u001b[0m response_body \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1390\u001b[0m     response\u001b[38;5;241m.\u001b[39mresponse_stream[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1391\u001b[0m )\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\google\\genai\\_api_client.py:1222\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[1;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[0;32m   1221\u001b[0m     retry \u001b[38;5;241m=\u001b[39m tenacity\u001b[38;5;241m.\u001b[39mRetrying(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mretry_kwargs)\n\u001b[1;32m-> 1222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_once, http_request, stream)\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\tenacity\\__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\tenacity\\__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\tenacity\\__init__.py:420\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\tenacity\\__init__.py:187\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.0\\lib\\concurrent\\futures\\_base.py:438\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.0\\lib\\concurrent\\futures\\_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\tenacity\\__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 480\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\google\\genai\\_api_client.py:1201\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m   1194\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m   1195\u001b[0m     method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   1196\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1199\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m   1200\u001b[0m )\n\u001b[1;32m-> 1201\u001b[0m \u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m   1203\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m   1204\u001b[0m )\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\google\\genai\\errors.py:121\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[1;34m(cls, response)\u001b[0m\n\u001b[0;32m    119\u001b[0m   response_json \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mbody_segments[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\google\\genai\\errors.py:146\u001b[0m, in \u001b[0;36mAPIError.raise_error\u001b[1;34m(cls, status_code, response_json, response)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m--> 146\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n",
      "\u001b[1;31mClientError\u001b[0m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 8.562794299s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mChatGoogleGenerativeAIError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Test 1: Simple stock price query ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the stock price of MSFT?\u001b[39m\u001b[38;5;124m\"\u001b[39m}]}\n\u001b[1;32m----> 4\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3065\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3066\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3068\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3069\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3070\u001b[0m     config,\n\u001b[0;32m   3071\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3072\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3075\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3076\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3077\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3078\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3079\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3080\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3081\u001b[0m ):\n\u001b[0;32m   3082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3083\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2641\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2642\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2643\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2644\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2645\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2646\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2647\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2648\u001b[0m ):\n\u001b[0;32m   2649\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2650\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2651\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2652\u001b[0m     )\n\u001b[0;32m   2653\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 656\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 400\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m, in \u001b[0;36mchatbot\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchatbot\u001b[39m(state: State) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m State:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[43mllm_with_tools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]}\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5548\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5541\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5546\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5547\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5549\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5550\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5551\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5552\u001b[0m     )\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:2529\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.invoke\u001b[1;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[0;32m   2526\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are already defined.code_execution tool can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2527\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m-> 2529\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    392\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AIMessage:\n\u001b[0;32m    393\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    396\u001b[0m         cast(\n\u001b[0;32m    397\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 398\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    399\u001b[0m                 [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    400\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    401\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    402\u001b[0m                 tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    403\u001b[0m                 metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    404\u001b[0m                 run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    405\u001b[0m                 run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    406\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    407\u001b[0m             )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    408\u001b[0m         )\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[0;32m    409\u001b[0m     )\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1110\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1115\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1116\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    926\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 927\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    928\u001b[0m                 m,\n\u001b[0;32m    929\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    930\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    931\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    932\u001b[0m             )\n\u001b[0;32m    933\u001b[0m         )\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1219\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1221\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1222\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1223\u001b[0m     )\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1225\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:3044\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m   3040\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m   3041\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest,\n\u001b[0;32m   3042\u001b[0m     )\n\u001b[0;32m   3043\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3044\u001b[0m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[1;32me:\\Work\\cursor\\LLM\\langgraph-example\\.venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:145\u001b[0m, in \u001b[0;36m_handle_client_error\u001b[1;34m(e, request)\u001b[0m\n\u001b[0;32m    143\u001b[0m model_name \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError calling model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mChatGoogleGenerativeAIError\u001b[0m: Error calling model 'gemini-2.5-flash-lite' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 8.562794299s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}"
     ]
    }
   ],
   "source": [
    "# Test 1: Simple query to verify tool calling works\n",
    "print(\"=== Test 1: Simple stock price query ===\")\n",
    "state = {\"messages\": [{\"role\": \"user\", \"content\": \"What is the stock price of MSFT?\"}]}\n",
    "state = graph.invoke(state)\n",
    "print(state[\"messages\"][-1].content)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eaa42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: With system message to help LLM understand it should use tools\n",
    "print(\"=== Test 2: Calculate cost with system message ===\")\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant with access to stock price tools. Use the available tools to fetch stock prices when needed to answer questions. You can perform calculations based on the stock prices you fetch.\"},\n",
    "        {\"role\": \"user\", \"content\": \"If I want to buy 20 stocks of MSFT using the current price, how much will it cost?\"}\n",
    "    ]\n",
    "}\n",
    "state = graph.invoke(state)\n",
    "print(state[\"messages\"][-1].content)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec472f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Rephrase to avoid \"buy\" trigger\n",
    "print(\"=== Test 3: Calculate without 'buy' word ===\")\n",
    "state = {\"messages\": [{\"role\": \"user\", \"content\": \"Calculate the total cost of 20 MSFT shares at the current price.\"}]}\n",
    "state = graph.invoke(state)\n",
    "print(state[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
